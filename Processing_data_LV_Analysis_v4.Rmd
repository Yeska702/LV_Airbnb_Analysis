---
title: "Las Vegas Airbnb Data Process and Analysis"
author: "Marcos"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setting up my environment

```{r loading packages, warning=FALSE}

library(tidyverse)
library(dplyr)
library(ggplot2)
library(lubridate)
library(scales)

```



Importing the date into R

```{r Importing Data}

# re-naming the data 
LV_Airbnb<-read.csv("LV_listings.csv")
LV_Calendar<-read.csv("LV_calendar.csv.gz")


```


Exploring the data from LV_Airbnb and LV_Calendar
```{r Exploring the data set}

glimpse(LV_Airbnb)
glimpse(LV_Calendar)

```


## Data Cleaning 

Exploring the data in LV_Airbnb we can remove sensitive and any irrelevant 
information we do not need for this analysis. We are also removing price from 
LV_Airbnb because we already have price in LV_Calendar which are data specific

```{r Data Cleaning}

RM_LV_listing<- LV_Airbnb[, !(names(LV_Airbnb) %in%
                                 c("host_name","neighbourhood_group", 
                                   "number_of_reviews", "last_review",
                                   "reviews_per_month", "number_of_reviews_ltm",
                                   "license", "price", "name", "minimum_nights"))]

# self check to make sure those column where removed from RM_LV_listings
glimpse(RM_LV_listing)


# now check for any empty data Within RM_LV_listing and LV_Calendar
colSums(is.na(RM_LV_listing))
# since we only have 3 missing data we leave it
colSums(is.na(LV_Calendar))




# Next we move on to the LV_Calendar dataset which contains the majority of the
# data required for our analysis
str(LV_Calendar$date)

# reformat date
LV_Calendar$date<- as.Date(LV_Calendar$date)

# reformat price gsub function removes $ and ,
LV_Calendar$price<- as.numeric(gsub("[$,]", "", LV_Calendar$price))

# check that conversion was made
class(LV_Calendar$price)
class(LV_Calendar$date)



# find earliest and latest date we see the earliest date is Sept 2024 
# and the lastest is Sept 2025
min(LV_Calendar$date)
max(LV_Calendar$date)


# now we merge both dataset into one.
merged_data<- merge(LV_Calendar, RM_LV_listing, by.x = "listing_id",
                    by.y = "id", all.x = TRUE)


#check that the data was merged into on
glimpse(merged_data)

```

##  Analyzing and Sharing 

```{r  checking avalable Airbnb }
 
# here we are counting how many Airbnb are available = TRUE in each month
monthly_counts <- merged_data %>% 
  mutate(month = floor_date(date, "month")) %>% 
  filter(available == "t") %>% 
  group_by(month) %>% 
  summarise(unique_listings = n_distinct(listing_id))


# Looking at the line graph we have here we can see, during the winter months there
# are a lot of available Airbnb. We see the number of rooms available stars
# to decline during the summer 
ggplot(data = monthly_counts) +
  geom_line(mapping = aes(x= month, y = unique_listings)) +
  # scale force the ggplot to print the months from  Sept 2024 to Sept 2025
  scale_x_date(
    breaks = seq(as.Date("2024-09-01"), as.Date("2025-09-01"), by = "1 month"),
    # this part will print out Month as Month / year
    labels = date_format("%b %y") # used to format how dates appear in x-axis
  ) +
  labs(title = "Monthly Listings", x = "Months/Year", y = "Unique Listings")


```


```{r average price}


# we check the average price of each Airbnb that has been booked. Any Airbnb that is
# available we do not count. This shows us a Demand trend 
ave_price <- merged_data %>% 
  mutate(month = floor_date(date, "month")) %>% 
 filter(available == "f") %>% 
  group_by(month) %>% 
  summarise(average_price = mean( price, na.rm = TRUE))



# As we see in the line graph the average price of Airbnb skyrockets to the moon
# during Dec 2024 and Jan 2025
ggplot( data =  ave_price) +
  geom_line( mapping = aes( x = month, y = average_price)) +
  scale_x_date(
    breaks = seq(as.Date("2024-09-01"), as.Date("2025-09-01"), by = "1 month"),
    labels = date_format("%b %y")
  ) +
  labs(title = "Average Price", x = "Months/Year", y = "Average Price")



```




```{r neighborhood ave. price}

# Know we check the average price of each Neighborhood in Las Vegas
ave_neighber_prices <- merged_data %>% 
  mutate(month = floor_date(date, "month")) %>% 
  #using false to count only those Airbnb that have been booked
  filter(available == "f") %>% 
  group_by(month, neighbourhood) %>% 
  #this .group tell summarize we do not want this data to be grouped anymore
  # and we only need the clean date frame. If we do not do this it leads to an error
  summarise(average_price = mean(price, na.rm = TRUE), .groups = "drop")


ggplot( data =ave_neighber_prices) + 
  geom_line( mapping = aes(x = month, y = average_price, color = neighbourhood)) +
  #this line of code makes the color more vibrant
  scale_color_viridis_d( option = "turbo") +
  scale_x_date(
    breaks = seq(as.Date("2024-09-01"), as.Date("2025-09-01"), by = "1 month"),
    labels = date_format("%b %y")
  ) +
  labs(title = "Average Price", x = "Months/Year", y = "Average Price")
  

```


When analyzing the average price across neighborhoods in Las Vegas, we can find 
that the most expensive areas to stay in are located within unincorporated
regions. These neighborhoods are Paradise, Spring Valley, Enterprise,
Winchester and Whitney. 


## Extracting the data for futher analysis

```{r Extracting data}


# using the write function export a csv file to use in Tableau
write.csv(merged_data, "LV_Airbnb_Analysis.csv", row.names = FALSE)


```




